{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaiKzsSw4FBM"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wak76xYYUdXE",
        "outputId": "35f3a421-84fc-4bf9-d07c-d81960d874b4"
      },
      "outputs": [],
      "source": [
        "!pip install -q cassandra-driver\n",
        "!pip install -q cassio>=0.1.1\n",
        "!pip install -q gradientai --upgrade\n",
        "!pip install -q llama-index\n",
        "!pip install -q pypdf\n",
        "!pip install -q tiktoken==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install llama-index --upgrade --no-cache-dir --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install llama-index-llms-gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install llama-index-embeddings-gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install gradientai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "# from google.colab import userdata\n",
        "\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = 'CK1zDOU4BQ03NoMJMUDndWM8oAoNFMpm'\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] =  \"55708ca1-7b2b-42b1-ae1b-7d75ef4bc8c7_workspace\"\n",
        "\n",
        "\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from cassandra.cluster import Cluster\n",
        "from llama_index.core import ServiceContext\n",
        "from llama_index.core import set_global_service_context\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
        "from llama_index.embeddings.gradient import GradientEmbedding\n",
        "from llama_index.llms.gradient import GradientBaseModelLLM\n",
        "# from llama_index.vector_stores import CassandraVectorStore\n",
        "\n",
        "# This secure connect bundle is autogenerated when you donwload your SCB,\n",
        "# if yours is different update the file name below\n",
        "import json\n",
        "\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-nlp.zip'\n",
        "}\n",
        "\n",
        "# This token json file is autogenerated when you donwload your token,\n",
        "# if yours is different update the file name below\n",
        "with open(\"premkumarc1111@gmail.com-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")\n",
        "\n",
        "\n",
        "\n",
        "llm = GradientBaseModelLLM(\n",
        "    base_model_slug=\"llama2-7b-chat\",\n",
        "    max_tokens=400,\n",
        ")\n",
        "\n",
        "\n",
        "embed_model = GradientEmbedding(\n",
        "    gradient_access_token = os.environ[\"GRADIENT_ACCESS_TOKEN\"],\n",
        "    gradient_workspace_id = os.environ[\"GRADIENT_WORKSPACE_ID\"],\n",
        "    gradient_model_slug=\"bge-large\",\n",
        ")\n",
        "\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm = llm,\n",
        "    embed_model = embed_model,\n",
        "    chunk_size=256,\n",
        ")\n",
        "\n",
        "set_global_service_context(service_context)\n",
        "\n",
        "documents = SimpleDirectoryReader(\"docs\").load_data()\n",
        "print(f\"Loaded {len(documents)} document(s).\")\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        service_context=service_context)\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"what is the payment history\")\n",
        "print(response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iILdU7U4Hya"
      },
      "source": [
        "# Import OS & JSON Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "U02ytLrPA2rG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "# from google.colab import userdata\n",
        "\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = 'CK1zDOU4BQ03NoMJMUDndWM8oAoNFMpm'\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] =  \"55708ca1-7b2b-42b1-ae1b-7d75ef4bc8c7_workspace\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3IS4xyg4N63"
      },
      "source": [
        "# Import Cassandra & llama Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GhZ1NMr2z3vF"
      },
      "outputs": [],
      "source": [
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from cassandra.cluster import Cluster\n",
        "from llama_index.core import ServiceContext\n",
        "from llama_index.core import set_global_service_context\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
        "from llama_index.embeddings.gradient import GradientEmbedding\n",
        "from llama_index.llms.gradient import GradientBaseModelLLM\n",
        "# from llama_index.vector_stores import CassandraVectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q28fIUq91zED",
        "outputId": "c9eb44dd-64ff-467f-a870-b2c7f9b4bcef"
      },
      "outputs": [],
      "source": [
        "import cassandra\n",
        "print (cassandra.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuio1UWlEMkQ"
      },
      "source": [
        "# Connect to the VectorDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYn5am9c1zGS",
        "outputId": "e3443a91-2144-4980-cd57-f5d2a0b93b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.0.11-09ec37c912ed\n"
          ]
        }
      ],
      "source": [
        "# This secure connect bundle is autogenerated when you donwload your SCB,\n",
        "# if yours is different update the file name below\n",
        "import json\n",
        "\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-nlp.zip'\n",
        "}\n",
        "\n",
        "# This token json file is autogenerated when you donwload your token,\n",
        "# if yours is different update the file name below\n",
        "with open(\"premkumarc1111@gmail.com-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I8T-kjh4VoX"
      },
      "source": [
        "# Define the Gradient's Model Adapter for LLAMA-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "EksBmgQt36_v"
      },
      "outputs": [],
      "source": [
        "llm = GradientBaseModelLLM(\n",
        "    base_model_slug=\"llama2-7b-chat\",\n",
        "    max_tokens=400,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPTqOwXZ4aLy"
      },
      "source": [
        "# Configure Gradient embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "38_uBhIy2XtA"
      },
      "outputs": [],
      "source": [
        "embed_model = GradientEmbedding(\n",
        "    gradient_access_token = os.environ[\"GRADIENT_ACCESS_TOKEN\"],\n",
        "    gradient_workspace_id = os.environ[\"GRADIENT_WORKSPACE_ID\"],\n",
        "    gradient_model_slug=\"bge-large\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "mf7hu0cE2VKy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\PRKUMAR\\AppData\\Local\\Temp\\ipykernel_20580\\3337229202.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(\n"
          ]
        }
      ],
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    llm = llm,\n",
        "    embed_model = embed_model,\n",
        "    chunk_size=256,\n",
        ")\n",
        "\n",
        "set_global_service_context(service_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3AEoS-t4t6f"
      },
      "source": [
        "# Load the PDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFXZvFaQ25kE",
        "outputId": "1aa41b4e-86a6-4f34-ab25-0ae809cd745e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2 document(s).\n"
          ]
        }
      ],
      "source": [
        "documents = SimpleDirectoryReader(\"docs\").load_data()\n",
        "print(f\"Loaded {len(documents)} document(s).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns8r13uw4vko"
      },
      "source": [
        "# Setup and Query Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "YT9wD9sQ25nv"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        service_context=service_context)\n",
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import VectorStoreIndex class\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 50  # Adjust as needed based on your system resources and processing time\n",
        "\n",
        "\n",
        "\n",
        "# Determine the total number of batches\n",
        "total_batches = (len(documents) + batch_size - 1) // batch_size\n",
        "\n",
        "# Initialize an empty list to store batch indexes\n",
        "batch_indexes = []\n",
        "\n",
        "# Process documents in batches\n",
        "for i in range(total_batches):\n",
        "    start_index = i * batch_size\n",
        "    end_index = min((i + 1) * batch_size, len(documents))\n",
        "    batch_documents = documents[start_index:end_index]\n",
        "\n",
        "    # Create VectorStoreIndex from batch documents\n",
        "    batch_index = VectorStoreIndex.from_documents(batch_documents, service_context=service_context)\n",
        "    batch_indexes.append(batch_index)\n",
        "\n",
        "# Merge batch indexes into a single index\n",
        "merged_index = batch_indexes[0]  # Initialize with the first batch index\n",
        "\n",
        "for index in batch_indexes[1:]:\n",
        "    merged_index = merged_index.merge(index)\n",
        "\n",
        "# Create query engine from merged index\n",
        "query_engine = merged_index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVYy24TR2VSM",
        "outputId": "2fee6862-cdc5-4126-b2c5-8a87e96eace6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the context information provided, the payment history for the user is as follows:\n",
            "\n",
            "* 29-FEB: 631.60\n",
            "* 31-JAN: 706.82\n",
            "* 31-DEC: 706.82\n",
            "\n",
            "Therefore, the payment history for the user shows three payments made in February, January, and December, respectively, with the amounts being 631.60, 706.82, and 706.82, respectively.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"what is the payment history\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRyW0E5N4DiX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
